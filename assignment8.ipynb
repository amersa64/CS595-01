{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titianic Dataset Description\n",
    "The sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n",
    "\n",
    "One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n",
    "\n",
    "Number of Objects = 1309 \n",
    "Number of Features = 10\n",
    "train and test Split is 1/3 by 2/3\n",
    "\n",
    "### Variable Definition\tKey\n",
    "* Survived\tSurvival\t0 = No, 1 = Yes\n",
    "* pclass\tTicket class\t1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "* sex\tgender\t\n",
    "* Age\tAge in years\t\n",
    "* sibsp \t# of siblings / spouses aboard the Titanic\t\n",
    "* parch\t  # of parents / children aboard the Titanic\t\n",
    "* ticket\tTicket number\t\n",
    "* fare\tPassenger fare\t\n",
    "* cabin\tCabin number\t\n",
    "* embarked\tPort of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton\n",
    "\n",
    "### Variable Notes\n",
    "\n",
    "pclass: A proxy for socio-economic status (SES)\n",
    "1st = Upper\n",
    "2nd = Middle\n",
    "3rd = Lower\n",
    "\n",
    "age: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n",
    "\n",
    "sibsp: The dataset defines family relations in this way...\n",
    "Sibling = brother, sister, stepbrother, stepsister\n",
    "Spouse = husband, wife (mistresses and fianc√©s were ignored)\n",
    "\n",
    "parch: The dataset defines family relations in this way...\n",
    "Parent = mother, father\n",
    "Child = daughter, son, stepdaughter, stepson\n",
    "Some children travelled only with a nanny, therefore parch=0 for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import numpy as np\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv', index_col='PassengerId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binarize features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dropping columns that have confusing features\n",
    "data.drop(['Name', 'Ticket'], axis = 1, inplace = True)\n",
    "# chaning the Cabin feature to a binary feature of having or not having a cabin\n",
    "data['hasCabin'] = data['Cabin'].apply(lambda x:0 if type(x) == float else 1)\n",
    "data.drop(['Cabin'], axis = 1, inplace=True)\n",
    "# binarizing the sex feature\n",
    "data['Sex'] = data['Sex'].map({'female':0, 'male':1}).astype(int)\n",
    "#binarizing the Pclass feature to 1 if 1st class and 0 if 2nd or 3rd class\n",
    "data['Pclass'] = data['Pclass'].map({1:1, 2:0 , 3:0}).astype(int)\n",
    "#binarzing the Age features to be 0 if less than mean or 1 greater than mean\n",
    "data['Age'] = data['Age'].apply(lambda x: 0 if x<np.mean(data['Age']) else 1)\n",
    "#binarizing the Embarked feature to 1 if S 0 otherwise\n",
    "#I chose to binarize this way because of the unequal distribtuion of values\n",
    "data['Embarked'] = data['Embarked'].fillna('S')\n",
    "data['EmbarkedS'] = data['Embarked'].map({'S':1, 'C':0, 'Q':0}).astype(int)\n",
    "data.drop(['Embarked'], axis = 1, inplace=True)\n",
    "#binaring the Fare feature to 0 if less than mean and 1 if greater than\n",
    "data['Fare'] = data['Fare'].apply(lambda x: 0 if x< np.mean(data['Fare']) else 1)\n",
    "# binarizing the Parch and SibSp feature to one feature if isAlone or not\n",
    "data['FamilySize'] = data['SibSp'] + data['Parch']+1\n",
    "data['isAlone'] = data['FamilySize'].apply(lambda x: 1 if x==1 else 0)\n",
    "data.drop(['FamilySize', 'Parch', 'SibSp'], inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# spliting the data into training and testing\n",
    "train_x, test_x, train_y, test_y =train_test_split(data.drop('Survived', axis = 1),data['Survived'], test_size = 0.33, random_state= 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training BernoulliNB classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = BernoulliNB()\n",
    "clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accurary is  0.743288590604\n",
      "test accurary is  0.769491525424\n"
     ]
    }
   ],
   "source": [
    "print(\"train accurary is \", clf.score(train_x,train_y))\n",
    "print(\"test accurary is \", clf.score(test_x,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_class_prior = clf.class_log_prior_[0]-clf.class_log_prior_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_1_yes=[math.exp(x)for x in clf.feature_log_prob_[0,:]]\n",
    "features_1_no = [math.exp(x)for x in clf.feature_log_prob_[1,:]]\n",
    "features_0_yes = [ 1-x for x in features_1_yes]\n",
    "features_0_no = [1-x for x in features_1_no]\n",
    "ln_features_0 = [np.log(features_0_yes[i]/features_0_no[i]) for i in range(0,len(features_0_no))]\n",
    "ln_features_1 = [np.log(features_1_yes[i]/features_1_no[i]) for i in range(0,len(features_0_no))]\n",
    "ln_features=[ln_features_0,ln_features_1]\n",
    "#ln_features.append(ln_features_0)\n",
    "#ln_features.append(ln_features_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_evidence_calc(obj):\n",
    "    positive_log_evidence = []\n",
    "    negative_log_evidence = []\n",
    "    for i,value in enumerate(obj):\n",
    "        if ln_features[value][i]>0:\n",
    "            positive_log_evidence.append((ln_features[value][i],i))\n",
    "        else:\n",
    "            negative_log_evidence.append((ln_features[value][i],i))\n",
    "    return(positive_log_evidence,negative_log_evidence)\n",
    "def features_pos(pos,obj):\n",
    "    pos.sort(key=lambda tup: tup[0])\n",
    "    pos_feature_1 = \"\"\n",
    "    pos_feature_2 = \"\"\n",
    "    if len(pos)>0:\n",
    "        pos_feature_1 = train_x.columns[pos[len(pos)-1][1]]\n",
    "        if(len(pos)>1):\n",
    "            pos_feature_2 = train_x.columns[pos[len(pos)-2][1]]\n",
    "            return (pos_feature_1,obj[pos_feature_1],pos_feature_2,obj[pos_feature_2])\n",
    "    return\n",
    "\n",
    "def features_neg(pos,obj):\n",
    "    pos.sort(key=lambda tup: tup[0])\n",
    "    pos_feature_1 = \"\"\n",
    "    pos_feature_2 =\"\"\n",
    "    if len(pos)>0:\n",
    "        pos_feature_1 = train_x.columns[pos[0][1]]\n",
    "        if(len(pos)>1):\n",
    "            pos_feature_2 = train_x.columns[pos[1][1]]\n",
    "            return (pos_feature_1,obj[pos_feature_1],pos_feature_2,obj[pos_feature_2])\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.The most positive with respect to the probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass       0\n",
      "Sex          1\n",
      "Age          1\n",
      "Fare         0\n",
      "hasCabin     0\n",
      "EmbarkedS    1\n",
      "isAlone      1\n",
      "Name: 440, dtype: int64\n",
      "total positive log-evidence=  2.96272381509\n",
      "total negative log-evidence=  0\n",
      "top 2 features values that contribute most to the positive evidence  ('Sex', 1, 'hasCabin', 0)\n",
      "top 2 features values that contribute most to the negative evidence  None\n",
      "probability distribution =  [ 0.95086142  0.04913858]\n"
     ]
    }
   ],
   "source": [
    "predicted_prob = clf.predict_proba(test_x)\n",
    "index = np.argmax(predicted_prob[:,0])\n",
    "obj = test_x.iloc[index,]\n",
    "print(obj)\n",
    "print(\"total positive log-evidence= \",log_class_prior+sum(i for i, _ in log_evidence_calc(obj)[0]))\n",
    "print(\"total negative log-evidence= \",sum(i for i, _ in log_evidence_calc(obj)[1]))\n",
    "print(\"top 2 features values that contribute most to the positive evidence \", features_pos(log_evidence_calc(obj)[0],obj))\n",
    "print(\"top 2 features values that contribute most to the negative evidence \", features_neg(log_evidence_calc(obj)[1],obj))\n",
    "print(\"probability distribution = \", predicted_prob[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.The most negative object with respect to the probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass       1\n",
      "Sex          0\n",
      "Age          0\n",
      "Fare         1\n",
      "hasCabin     1\n",
      "EmbarkedS    0\n",
      "isAlone      0\n",
      "Name: 312, dtype: int64\n",
      "total positive log-evidence=  0.521578415542\n",
      "total negative log-evidence=  -5.27727683209\n",
      "top 2 features values that contribute most to the positive evidence  None\n",
      "top 2 features values that contribute most to the negative evidence  ('Sex', 0, 'hasCabin', 1)\n",
      "probability distribution =  [ 0.00852916  0.99147084]\n"
     ]
    }
   ],
   "source": [
    "index = np.argmax(predicted_prob[:,1])\n",
    "obj = test_x.iloc[index]\n",
    "print(obj)\n",
    "print(\"total positive log-evidence= \",log_class_prior+sum(i for i, _ in log_evidence_calc(obj)[0]))\n",
    "print(\"total negative log-evidence= \",sum(i for i, _ in log_evidence_calc(obj)[1]))\n",
    "print(\"top 2 features values that contribute most to the positive evidence \", features_pos(log_evidence_calc(obj)[0],obj))\n",
    "print(\"top 2 features values that contribute most to the negative evidence \", features_neg(log_evidence_calc(obj)[1],obj))\n",
    "print(\"probability distribution = \", predicted_prob[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_evidence_objects_list= []\n",
    "neg_evidence_objects_list= []\n",
    "for i in range(0,len(test_x)):\n",
    "    pos_evidence_objects_list.append(log_class_prior+sum(i for i, _ in log_evidence_calc(test_x.iloc[i])[0]))\n",
    "    neg_evidence_objects_list.append(sum(i for i, _ in log_evidence_calc(test_x.iloc[i])[1]))\n",
    "pos_evidence_objects_list = np.array(pos_evidence_objects_list)\n",
    "neg_evidence_objects_list = np.array(neg_evidence_objects_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. The object that has the largest positive evidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass       0\n",
      "Sex          1\n",
      "Age          1\n",
      "Fare         0\n",
      "hasCabin     0\n",
      "EmbarkedS    1\n",
      "isAlone      1\n",
      "Name: 440, dtype: int64\n",
      "total positive log-evidence=  2.96272381509\n",
      "total negative log-evidence=  0\n",
      "top 2 features values that contribute most to the positive evidence  ('Sex', 1, 'hasCabin', 0)\n",
      "top 2 features values that contribute most to the negative evidence  None\n",
      "probability distribution =  [ 0.95086142  0.04913858]\n"
     ]
    }
   ],
   "source": [
    "index = np.argmax(pos_evidence_objects_list)\n",
    "obj = test_x.iloc[index]\n",
    "print(obj)\n",
    "print(\"total positive log-evidence= \",log_class_prior+sum(i for i, _ in log_evidence_calc(obj)[0]))\n",
    "print(\"total negative log-evidence= \",sum(i for i, _ in log_evidence_calc(obj)[1]))\n",
    "print(\"top 2 features values that contribute most to the positive evidence \", features_pos(log_evidence_calc(obj)[0],obj))\n",
    "print(\"top 2 features values that contribute most to the negative evidence \", features_neg(log_evidence_calc(obj)[1],obj))\n",
    "print(\"probability distribution = \", predicted_prob[index,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. The object that has the largest (in magnitude) negative evidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass       1\n",
      "Sex          0\n",
      "Age          0\n",
      "Fare         1\n",
      "hasCabin     1\n",
      "EmbarkedS    0\n",
      "isAlone      0\n",
      "Name: 312, dtype: int64\n",
      "total positive log-evidence=  0.521578415542\n",
      "total negative log-evidence=  -5.27727683209\n",
      "top 2 features values that contribute most to the positive evidence  None\n",
      "top 2 features values that contribute most to the negative evidence  ('Sex', 0, 'hasCabin', 1)\n",
      "probability distribution =  [ 0.00852916  0.99147084]\n"
     ]
    }
   ],
   "source": [
    "index = np.argmin(neg_evidence_objects_list)\n",
    "obj = test_x.iloc[index]\n",
    "print(obj)\n",
    "print(\"total positive log-evidence= \",log_class_prior+sum(i for i, _ in log_evidence_calc(obj)[0]))\n",
    "print(\"total negative log-evidence= \",sum(i for i, _ in log_evidence_calc(obj)[1]))\n",
    "print(\"top 2 features values that contribute most to the positive evidence \", features_pos(log_evidence_calc(obj)[0],obj))\n",
    "print(\"top 2 features values that contribute most to the negative evidence \", features_neg(log_evidence_calc(obj)[1],obj))\n",
    "print(\"probability distribution = \", predicted_prob[index,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Even though we see that we have some value for the total postive evidence but no corresponding feature and thats just due to class prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. The most uncertain object (the probabilities are closest to 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass       1\n",
      "Sex          1\n",
      "Age          1\n",
      "Fare         1\n",
      "hasCabin     0\n",
      "EmbarkedS    0\n",
      "isAlone      1\n",
      "Name: 494, dtype: int64\n",
      "total positive log-evidence=  2.21020960302\n",
      "total negative log-evidence=  -2.15556740553\n",
      "top 2 features values that contribute most to the positive evidence  ('Sex', 1, 'hasCabin', 0)\n",
      "top 2 features values that contribute most to the negative evidence  ('Pclass', 1, 'Fare', 1)\n",
      "probability distribution =  [ 0.51365715  0.48634285]\n"
     ]
    }
   ],
   "source": [
    "clearPRE = np.abs(np.add(predicted_prob[:,1],-0.5))\n",
    "index = np.argmin(clearPRE)\n",
    "obj = test_x.iloc[index]\n",
    "print(obj)\n",
    "print(\"total positive log-evidence= \",log_class_prior+sum(i for i, _ in log_evidence_calc(obj)[0]))\n",
    "print(\"total negative log-evidence= \",sum(i for i, _ in log_evidence_calc(obj)[1]))\n",
    "print(\"top 2 features values that contribute most to the positive evidence \", features_pos(log_evidence_calc(obj)[0],obj))\n",
    "print(\"top 2 features values that contribute most to the negative evidence \", features_neg(log_evidence_calc(obj)[1],obj))\n",
    "print(\"probability distribution = \", predicted_prob[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
