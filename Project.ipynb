{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import random\n",
    "import pandas\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import linear_model\n",
    "from astropy.table import Table, Column\n",
    "import numpy as np\n",
    "import graphviz \n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import sys\n",
    "import nltk\n",
    "import re\n",
    "import math\n",
    "words = set(nltk.corpus.words.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pandas.read_csv('Chat_Text_Data.csv')\n",
    "data = data.iloc[0:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import EnglishStemmer\n",
    "\n",
    "stemmer = EnglishStemmer()\n",
    "analyzer = CountVectorizer(preprocessor=lambda x: re.sub(r'(\\d[\\d\\.])+', '', x.lower()),\n",
    "                            stop_words='english',lowercase=True,ngram_range=(1,1),\n",
    "                            token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b').build_analyzer()\n",
    "\n",
    "def stemmed_words(doc):\n",
    "    return (stemmer.stem(w) for w in analyzer(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer=stemmed_words,min_df=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = vectorizer.fit_transform(data['Text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aaa', 'actual', 'ador', 'airlin', 'alexa', 'allow', 'amaz', 'american', 'angel', 'angelina', 'anniston', 'announc', 'anyway', 'appar', 'arrog', 'ass', 'aunt', 'awesom', 'balboa', 'basic', 'beat', 'beauti', 'believ', 'big', 'bike', 'bitch', 'black', 'blame', 'blond', 'blue', 'bore', 'boston', 'bridg', 'btw', 'bug', 'bush', 'cal', 'call', 'carlo', 'clinton', 'clip', 'colleg', 'color', 'come', 'commerci', 'cool', 'crappi', 'crazi', 'cruis', 'cs', 'depart', 'doe', 'don', 'drive', 'dumb', 'element', 'emblem', 'end', 'episod', 'excel', 'excit', 'experi', 'face', 'fact', 'fall', 'famili', 'far', 'faulti', 'fav', 'feel', 'food', 'francisco', 'friend', 'fuck', 'fun', 'game', 'gearshift', 'geico', 'general', 'giant', 'go', 'god', 'goe', 'good', 'got', 'great', 'harvard', 'hate', 'heard', 'hillari', 'hilton', 'histori', 'hk', 'home', 'honda', 'hope', 'hous', 'ignit', 'interlock', 'interview', 'isn', 'japan', 'jennif', 'jo', 'joli', 'just', 'karen', 'key', 'kid', 'kill', 'kind', 'kinda', 'know', 'kobe', 'laker', 'lauer', 'left', 'legal', 'let', 'librari', 'lifetim', 'like', 'lil', 'littl', 'lol', 'london', 'look', 'los', 'love', 'macbook', 'major', 'make', 'man', 'manag', 'market', 'markham', 'mastercard', 'matt', 'mav', 'mayo', 'mean', 'mental', 'million', 'miss', 'missouri', 'mit', 'moment', 'move', 'music', 'need', 'new', 'obvious', 'oh', 'old', 'overr', 'pack', 'pari', 'park', 'pass', 'peopl', 'person', 'pictur', 'pink', 'pleas', 'pomm', 'posit', 'post', 'pretti', 'prius', 'pro', 'problem', 'purdu', 'realli', 'relat', 'remind', 'remov', 'ride', 'rock', 'round', 'rule', 'san', 'say', 'school', 'scientolog', 'seattl', 'second', 'shanghai', 'small', 'smart', 'sound', 'spur', 'squar', 'step', 'stone', 'stuff', 'stupid', 'suck', 'summer', 'talk', 'terribl', 'think', 'thinkpad', 'thought', 'time', 'today', 'told', 'tom', 'took', 'tour', 'toyota', 'traffic', 'train', 'turn', 'tv', 'ucla', 'ugli', 'unassum', 'use', 'useless', 'usual', 've', 'vehicl', 'want', 'way', 'winner', 'woman', 'women', 'work', 'world', 'wrong', 'year', 'yep']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names())\n",
    "df = pandas.DataFrame(res.toarray(),columns=vectorizer.get_feature_names(),dtype=float)\n",
    "df['rationale']=\"\"\n",
    "df['label']=0\n",
    "#df = pandas.read_csv('labeled_instances.csv',index_col=False)\n",
    "df.head()\n",
    "df.to_csv('main_training.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amer\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df[100:300]['rationale']=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def demphsizer(row, rationale):\n",
    "    demphsizees = []\n",
    "    for col in vectorizer.get_feature_names():\n",
    "        if row[col]==1 and not col==rationale:\n",
    "            demphsizees.append(col)\n",
    "    return demphsizees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def label():\n",
    "    for i in range(df.shape[0]):\n",
    "        if df.loc[i]['rationale']=='':\n",
    "            print(data.iloc[i]['Text'])\n",
    "            word = input()\n",
    "            if word == 'exit':\n",
    "                df.to_csv('labeled_instances_1.csv')\n",
    "                break\n",
    "            label = input()\n",
    "            if label == -1:\n",
    "                df.to_csv('labeled_instances_1.csv')\n",
    "                break\n",
    "            df.set_value(i,'label',label)\n",
    "            df.set_value(i,'rationale',word)\n",
    "#            df.set_value(i,word,100)           \n",
    "#            for col_name in demphsizer(df.loc[i], word):\n",
    "#                df.set_value(i,col_name, df.loc[i][col_name])\n",
    "    df.to_csv('labeled_instances_1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love seattle..\n",
      "love\n",
      "1\n",
      "I love the London Little People, btw.\n",
      "love\n",
      "1\n",
      "mastercard is stupid.\n",
      "stupid\n",
      "0\n",
      "I hate Paris Hilton..\n",
      "hate\n",
      "0\n",
      "Kinda want a toyota tacoma, i like them much.....\n",
      "like\n",
      "1\n",
      "I'd like to talk today about how much I hate Paris Hilton.....\n",
      "hate\n",
      "0\n",
      "I love MIT so much...\n",
      "love\n",
      "1\n",
      "have an awesome time at purdue!..\n",
      "awesome\n",
      "1\n",
      "Today, Hillary Clinton is lambasted in an extremely vulgar fashion by a World leader:\n",
      "vulgar\n",
      "0\n",
      "Then we had stupid trivia about San Francisco and sci fi tv so we left...\n",
      "stupid\n",
      "0\n",
      "I needed San Francisco but not until a month ago.\n",
      "needed\n",
      "1\n",
      "I want a tour of London on the back of that bike!\n",
      "want\n",
      "1\n",
      "I really hate Tom Cruise.\n",
      "hate\n",
      "0\n",
      "i went to look into the details about my graduation gear and when i came back my beautiful blue toyota PASS got a ticket for being 5 min.\n",
      "beautiful\n",
      "1\n",
      "TAKE THAT STUPID UCLA!!!!!!!..\n",
      "stupid\n",
      "0\n",
      "I hate Tom Cruise..\n",
      "hate\n",
      "0\n",
      "I used to like Tom Cruise but the Matt Lauer interview really turned me off.\n",
      "turned\n",
      "0\n",
      "Honda is excellent,'94 and up.\n",
      "excellent\n",
      "1\n",
      "Mind you, I blame the mother mit der early toilet training.\n",
      "blame\n",
      "0\n",
      "I used to love Tom Cruise.\n",
      "love\n",
      "1\n",
      "& i adore my little honda < 3.\n",
      "adore\n",
      "1\n",
      "boston college is good too < 33.\n",
      "good\n",
      "1\n",
      "I'd love a Toyota van..\n",
      "love\n",
      "1\n",
      "Honda is calling back some 423,344 vehicles in its home market of Japan over faulty key interlocks which allow keys to be removed from the ignition when the gearshift is in positions other than'park.\n",
      "faulty\n",
      "0\n",
      "San Francisco is great for that, too.\n",
      "great\n",
      "1\n",
      "I love UCLA but miss everyone from back home.\n",
      "love\n",
      "1\n",
      "I love the Los Angeles Lakers...\n",
      "love\n",
      "1\n",
      "usually, i can't at my house but i'm at the library but i moved into my aunts house in san carlos to go to school here because schools in san francisco sucks BIG TIME!\n",
      "suck\n",
      "0\n",
      "i want american express to let me check into rehab..\n",
      "rehab\n",
      "0\n",
      "I WANT MIT!!!!!!!!!!!!!!!!!!!!!!!!!!!!!..\n",
      "want\n",
      "1\n",
      "I like being at Purdue, not with my family.\n",
      "like\n",
      "1\n",
      "wow i love your aaa..\n",
      "love\n",
      "1\n",
      "Funny that harvard was almost more stressful than MY AUDITION!\n",
      "funny\n",
      "1\n",
      "Honda is calling back some 423,344 vehicles in its home market of Japan over faulty key interlocks which allow keys to be removed from the ignition when the gearshift is in positions other than'park.\n",
      "faulty\n",
      "0\n",
      "Lakers Suck ( actually Kobe Sucks...\n",
      "suck\n",
      "0\n",
      "and I still hate UCLA bankers..\n",
      "hate\n",
      "0\n",
      "AAA rocks.\n",
      "rocks\n",
      "1\n",
      "boston college is good too < 33.\n",
      "good\n",
      "1\n",
      "yes shanghai is such an ugly place.\n",
      "ugly\n",
      "0\n",
      "n metti wa gor wait me end up the ce,. then we hv dinner ga..... i love u galz say \" wait me \" aaa.\n",
      "love\n",
      "1\n",
      "Seattle sucks!!\n",
      "suck\n",
      "0\n",
      "And everybody knows I love Toyota!\n",
      "love\n",
      "1\n",
      "i got like 9 AAA's during the course of the tournament, ive never been that consistent in a tournament before.\n",
      "like\n",
      "1\n",
      "UCLA is a beautiful campus, and it feels great to be back in the classroom.\n",
      "beautiful\n",
      "1\n",
      "When I saw the letter that said 19,000 people applied, I no longer feel so crappy about the Harvard thing.\n",
      "crappy\n",
      "0\n",
      "Honda's just stupid.\n",
      "stupid\n",
      "0\n",
      "I really hate London, there are very few people here, and those who are here, I never see.\n",
      "hate\n",
      "0\n",
      "Yep, I'm still in London, which is pretty awesome: P Remind me to post the million and one pictures that I took when I get back to Markham!...\n",
      "awesome\n",
      "1\n",
      "We really need to competition between Visa / Mastercard to heat up enough that one of them drops their transaction fee..\n",
      "need\n",
      "1\n",
      "Stupid UCLA....\n",
      "stupid\n",
      "0\n",
      "I miss crossing London's bridges ( and am suffering severe case of London homesickness at the moment...! ).\n",
      "suffer\n",
      "0\n",
      "i need clothes before i look stupid @ lakers....\n",
      "stupid\n",
      "0\n",
      "i love seattle so much.\n",
      "love\n",
      "1\n",
      "I'm not crazy about HK either, but Shanghai is sounding awesome.\n",
      "awesome\n",
      "1\n",
      "I had to tape because my mom had to watch her stupid Boston Legal and its a new TV / VCR so I was taping the wrong channel.\n",
      "stupid\n",
      "0\n",
      "GEICO is a GREAT ride.\n",
      "great\n",
      "1\n",
      "i do i love angelina jolie!..\n",
      "love\n",
      "1\n",
      "I love Angelina Jolie.\n",
      "love\n",
      "1\n",
      "San Francisco Coffee rocks, yo!\n",
      "rock\n",
      "1\n",
      "Shanghai is boring..\n",
      "boring\n",
      "0\n",
      "the fact that i love paris hilton or like the color pink...\n",
      "love\n",
      "1\n",
      "I love geico commercials.\n",
      "love\n",
      "1\n",
      "Tom Cruise needs to suck it up and so does Scientology in general.\n",
      "suck\n",
      "0\n",
      "I loved the Lakers episode where he told that little blonde he wants to see a woman rule the world in his lifetime because women know how to look after the pack.\n",
      "loved\n",
      "1\n",
      "Purdue Band sucks.\n",
      "sucks\n",
      "0\n",
      "It's about the MacBook Pro, which is awesome and I want one, but I have my beloved iBook, and believe you me, I love it..\n",
      "awesome\n",
      "1\n",
      "I love the Toyota Prius.\n",
      "love\n",
      "1\n",
      "I'm a big fan of Lakers, so I kind of have all the schedule for this season which it's end in april...\n",
      "fan\n",
      "1\n",
      "i've been incredibly busy lately, but seattle is fucking awesome & i love it.\n",
      "awesome\n",
      "1\n",
      "i love seattle so much.\n",
      "love\n",
      "1\n",
      "but the macbook looks so awesome.\n",
      "awesome\n",
      "1\n",
      "I would love to go Shanghai with sister..\n",
      "love\n",
      "1\n",
      "I can only imagine, with the bloated egos and arrogant liberalism at Harvard, this effect was magnified...\n",
      "arrogant\n",
      "0\n",
      "stupid lakers....\n",
      "stupid\n",
      "0\n",
      "I like San Francisco, even though apparently we almost got jumped this past weekend.\n",
      "like\n",
      "1\n",
      "Today, when Monkee was backing out of the Milpitas Library's parking lot, some old asian man driving a Toyota was driving the wrong way.\n",
      "wrong\n",
      "0\n",
      "Honda is excellent,'94 and up.\n",
      "excellent\n",
      "1\n",
      "I can see why he might have had problems with Karen but Toyota Alexa is useless and Jo is MENTAL!!!\n",
      "useless\n",
      "0\n",
      "but the fact that it's in Boston kind of kills it, because Boston basically sucks....\n",
      "suck\n",
      "0\n",
      "I need some of that geico balboa stuff..\n",
      "need\n",
      "1\n",
      "i love my macbook...\n",
      "love\n",
      "1\n",
      "BOSTON SUCKS!!\n",
      "suck\n",
      "0\n",
      "I like being at Purdue, not with my family.\n",
      "like\n",
      "1\n",
      "i'd love to see the clips and lakers in the second round, though the winner would just be a stepping stone for the mavs or spurs...\n",
      "love\n",
      "1\n",
      "Oh, how I onced loved to make Harvard undergrads cry with my grammar skillz!!\n",
      "cry\n",
      "0\n",
      "The history here goes back to the summer of 1992, when the San Francisco Giants were terrible.\n",
      "terrible\n",
      "0\n",
      "angelina jolie is obviously a stupid ass...\n",
      "stupid\n",
      "0\n",
      "This means we beat out schools like MIT, which is amazing for a relatively small, unassuming lil'IS department.\n",
      "amazing\n",
      "1\n",
      "Oh my god I LOVE Pommes mit Mayo.\n",
      "love\n",
      "1\n",
      "and honda elements are assholes...\n",
      "assholes\n",
      "0\n",
      ". I'm pleased to announce that Boston sucked...\n",
      "sucked\n",
      "0\n",
      "As much as I hate Tom Cruise..\n",
      "hate\n",
      "0\n",
      "I hate United Airlines.....\n",
      "hate\n",
      "0\n",
      "I love MIT so much...\n",
      "love\n",
      "1\n",
      "I hate Paris Hilton.\n",
      "hate\n",
      "0\n",
      "I hate Paris Hilton.\n",
      "hate\n",
      "0\n",
      "but the fact that it's in Boston kind of kills it, because Boston basically sucks....\n",
      "sucks\n",
      "09\n",
      "the beautiful Harvard grad —..\n",
      "beautiful\n",
      "1\n",
      "At heart, what Hillary Clinton and Co. are doing is dismissing as a Bush fiction the idea of \" friendly \" Arab \" allies \" in the war of terror.\n",
      "terror\n",
      "0\n",
      "I need john and michelle back in seattle, my longtime buddies, my rock.\n",
      "buddies\n",
      "1\n",
      "I hated Boston.\n",
      "hated\n",
      "0\n",
      "stupid american airlines!!!.\n",
      "stupid\n",
      "0\n",
      "personally, i still love my 1999 toyota camry, 4 cylinder, 35mpg, gray, comfy, smooth, dependable....\n",
      "love\n",
      "1\n",
      "stupid kids and their need for Honda emblems):\n",
      "stupid\n",
      "0\n",
      "I'd like to talk today about how much I hate Paris Hilton.....\n",
      "hate\n",
      "0\n",
      "Hillary Clinton was arrogant and orally abusive to.\n",
      "arrogant\n",
      "0\n",
      " It's not like this is the first time it's happened, but Paris Hilton irks me to no end...\n",
      "irks\n",
      "0\n",
      "tom cruise sucks.\n",
      "sucks\n",
      "0\n",
      ", Boston is great...\n",
      "great\n",
      "1\n",
      "Harvard was fucking awesome missing it like hell.\n",
      "awesome\n",
      "1\n",
      "stupid lakers....\n",
      "stupid\n",
      "0\n",
      "Oh man, last night's Lakers playoff game was awesome.\n",
      "awesome\n",
      "1\n",
      "AH SHIITE I LOST FIFTY CENTS TO THE SUPERBOWL { I HATE YOU SEATTLE!!! }...\n",
      "hate\n",
      "0\n",
      "I love the London Little People, btw.\n",
      "love\n",
      "1\n",
      "I hate paris hilton too!\n",
      "hate\n",
      "0\n",
      "London was awesome our trip home..\n",
      "awesome\n",
      "1\n",
      "I love ucla.\n",
      "love\n",
      "1\n",
      "Cs: I've heard San Francisco is beautiful..\n",
      "beautiful\n",
      "1\n",
      "Ladies, feast your eyes on the black 2.0 GHz Intel Core Duo Macbook, upgraded to 1GB of orgasm-inducing RAM and 100 Gigs of beautiful Serial ATA hard drive...\n",
      "beautiful\n",
      "1\n",
      "I need some of that geico balboa stuff..\n",
      "need\n",
      "1\n",
      "I love Tom Cruise!\n",
      "love\n",
      "1\n",
      "I hate the Lakers...\n",
      "hate\n",
      "0\n",
      "I so want a MacBook.\n",
      "want\n",
      "1\n",
      "All san Francisco has are shitty little old apts in this price range...\n",
      "shitty\n",
      "0\n",
      "Also, Seattle is fucking amazing..\n",
      "amazing\n",
      "1\n",
      "macbook pro is sexy.\n",
      "sexy\n",
      "1\n",
      "I hate Tom Cruise..\n",
      "hate\n",
      "0\n",
      "I hate Paris Hilton.\n",
      "hate\n",
      "0\n",
      "stupid kids and their need for Honda emblems):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stupid\n",
      "0\n",
      "I love all the Lakers but Kobe is my fav!.\n",
      "love\n",
      "1\n",
      "UCLA was stupid.\n",
      "stupid\n",
      "1\n",
      "I used to like Tom Cruise but the Matt Lauer interview really turned me off.\n",
      "turned\n",
      "9\n",
      "Boston's been awesome.\n",
      "awesome\n",
      "1\n",
      "I also love Boston Legal...\n",
      "love\n",
      "1\n",
      "I actually want a volkswagen beetle.\n",
      "want\n",
      "1\n",
      "gawssh i hate london i hope he blows up and his guts fly everywhere and then birds eat his guts.\n",
      "hate\n",
      "0\n",
      ", Boston is great...\n",
      "geat\n",
      "1\n",
      "The history here goes back to the summer of 1992, when the San Francisco Giants were terrible.\n",
      "terrible\n",
      "0\n",
      "besides, UCLA was a stupid dream...\n",
      "stupid\n",
      "0\n",
      "I love Paris Hilton..\n",
      "love\n",
      "1\n",
      "Once again I'm slighted by the evil secretaries of UIUC.\n",
      "evil\n",
      "0\n",
      "I can see why he might have had problems with Karen but Toyota Alexa is useless and Jo is MENTAL!!!\n",
      "useless\n",
      "0\n",
      "Tom Cruise needs to suck it up and so does Scientology in general.\n",
      "suck\n",
      "0\n",
      "this stupid black honda..\n",
      "stupid\n",
      "0\n",
      "i love the geico ones...\n",
      "love\n",
      "1\n",
      "Apparently, MIT and Olin are awesome.\n",
      "awesome\n",
      "1\n",
      "Man if you cant sell angry lefty bullshit in San Francisco, you probably would be challenges to sell ass on a troop ship....\n",
      "angry\n",
      "0\n",
      "I do like the Dell Inspiron E1705...\n",
      "like\n",
      "1\n",
      "I used to like Tom Cruise but the Matt Lauer interview really turned me off.\n",
      "turned\n",
      "0\n",
      "The built-in mic for the ThinkPad is useless.\n",
      "useless\n",
      "0\n",
      "I'm loving Shanghai > > > ^ _ ^.\n",
      "loving\n",
      "1\n",
      "However you look at it, I've been here almost two weeks now and so far I absolutely love UCLA...\n",
      "love\n",
      "1\n",
      "And i've managed to cover all of my own food expenses as of thus far by working as Harvard's random task bitch -- doubly freaking sweet(\n",
      "sweet\n",
      "1\n",
      "berkley / oakland / san francisco were amazing...\n",
      "amazing\n",
      "1\n",
      "Cs: I've heard San Francisco is beautiful..\n",
      "beautiful\n",
      "1\n",
      "i love ucla!..\n",
      "love\n",
      "1\n",
      "I loved Boston and MIT so much and still do.\n",
      "loved\n",
      "1\n",
      "I love my 13 year old Toyota!..\n",
      "love\n",
      "1\n",
      "& i adore my little honda < 3.\n",
      "adore\n",
      "1\n",
      "I hate Hyundai.\n",
      "hate\n",
      "0\n",
      "If you can manage to coach while you're at Geico, that's awesome.\n",
      "awesome\n",
      "2\n",
      "I'm still not sure if I like London.\n",
      "like\n",
      "1\n",
      "This means we beat out schools like MIT, which is amazing for a relatively small, unassuming lil'IS department.\n",
      "amazing\n",
      "1\n",
      "i hate american airlines....\n",
      "hate\n",
      "0\n",
      "i knew i had crazy and stupid times in Seattle, and as much as i'd say tat i'm still partially fragile and lonely, i'm thru with it, for reals!!\n",
      "lonely\n",
      "0\n",
      "Let's face it, the New York Knicks are terrible.\n",
      "terrible\n",
      "0\n",
      "There is a Taste of China right by GEICO that has great food.\n",
      "great\n",
      "1\n",
      "I loved the Lakers episode where he told that little blonde he wants to see a woman rule the world in his lifetime because women know how to look after the pack.\n",
      "loved\n",
      "1\n",
      "I love Angelina Jolie and i love you even more, also your music on your site is my fav.\n",
      "love\n",
      "1\n",
      "Man: I'm progressive, but I like Hillary Clinton..\n",
      "like\n",
      "1\n",
      "I love Geico commercials and Capital One commercials.\n",
      "love\n",
      "1\n",
      "I want a tour of London on the back of that bike!\n",
      "want\n",
      "1\n",
      "i hate the Lakers too but this isn't a basketball blog, so i won't go into it).\n",
      "hate\n",
      "0\n",
      "MIT's Naxos Music Library subscription is AWESOME..\n",
      "awesome\n",
      "1\n",
      "But I miss Boston.\n",
      "miss\n",
      "1\n",
      "Stupid ass SONY Vaio LCD monitor finally burned out after 6 years...\n",
      "stupid\n",
      "0\n",
      "I love the Los Angeles LAKERS!!!.\n",
      "love\n",
      "1\n",
      "As much as I love the Lakers and Kobe, I still have to state the facts...\n",
      "love\n",
      "1\n",
      "well i'm gonna go enjoy being in seattle.....\n",
      "enjoy\n",
      "1\n",
      "i love seattle so much.\n",
      "love\n",
      "1\n",
      "My Purdue Cal friends are awesome!..\n",
      "awesome\n",
      "1\n",
      "Geico would be great, and I really hope that works out.\n",
      "great\n",
      "1\n",
      "Driving entailed driving through Harvard U, and horrible traffic on a Friday evening.\n",
      "horrible\n",
      "0\n",
      "tom cruise sucks.\n",
      "sucks\n",
      "0\n",
      "we have a boring as shit blue 2005 toyota carolla.\n",
      "boring\n",
      "0\n",
      "usually, i can't at my house but i'm at the library but i moved into my aunts house in san carlos to go to school here because schools in san francisco sucks BIG TIME!\n",
      "sucks\n",
      "0\n",
      "Have I told you I hate Tom Cruise?..\n",
      "hate\n",
      "0\n",
      "I like Honda...\n",
      "like\n",
      "1\n",
      "I hate Paris Hilton.\n",
      "hate\n",
      "0\n",
      "Yep, I'm still in London, which is pretty awesome: P Remind me to post the million and one pictures that I took when I get back to Markham!...\n",
      "awesome\n",
      "1\n",
      "my awesome honda....: -(.\n",
      "awesome\n",
      "1\n",
      "I need some of that geico balboa stuff..\n",
      "need\n",
      "1\n",
      "the fact that i love paris hilton or like the color pink...\n",
      "love\n",
      "1\n",
      "My current MacBook Pro is gorgeous.\n",
      "gorgeous\n",
      "1\n",
      "You are a fucking bitch and I think I may hate you even more than I hate Paris Hilton...\n",
      "hate\n",
      "0\n",
      "stupid lakers should have beat suns.....\n",
      "stupid\n",
      "0\n",
      "I hate the exodus of subarus and honda crv's and volvos.\n",
      "hate\n",
      "0\n",
      "tom cruise sucks.\n",
      "sucks\n",
      "0\n",
      "I can see why he might have had problems with Karen but Toyota Alexa is useless and Jo is MENTAL!!!\n",
      "useless\n",
      "0\n",
      "I loved Boston and MIT so much and still do.\n",
      "loved\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_csv('main_train_clean.csv',index_col=False)\n",
    "df = pandas.DataFrame.astype(df,dtype=float,errors='ignore')\n",
    "df['label'] = df['label'].astype('int')\n",
    "#df = df.apply(pandas.to_numeric,errors='ignore')\n",
    "#df.drop_duplicates(inplace=True)\n",
    "#df.to_csv('main_train_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train =df[0:150]\n",
    "df_test = df[150:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89855072463768115"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(df_train.drop(['label','rationale'], axis =1),df_train['label'])\n",
    "clf.score(df_test.drop(['label','rationale'], axis =1),df_test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(df_train.shape[0]):\n",
    "    word = stemmer.stem(df_train.loc[i]['rationale'])\n",
    "    for col_name in demphsizer(df_train.loc[i], word):\n",
    "        df_train.set_value(i,col_name, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaa</th>\n",
       "      <th>actual</th>\n",
       "      <th>ador</th>\n",
       "      <th>airlin</th>\n",
       "      <th>alexa</th>\n",
       "      <th>allow</th>\n",
       "      <th>amaz</th>\n",
       "      <th>american</th>\n",
       "      <th>angel</th>\n",
       "      <th>angelina</th>\n",
       "      <th>...</th>\n",
       "      <th>winner</th>\n",
       "      <th>woman</th>\n",
       "      <th>women</th>\n",
       "      <th>work</th>\n",
       "      <th>world</th>\n",
       "      <th>wrong</th>\n",
       "      <th>year</th>\n",
       "      <th>yep</th>\n",
       "      <th>rationale</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>like</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>awesome</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>awesome</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>hate</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>love</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 234 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aaa  actual  ador  airlin  alexa  allow  amaz  american  angel  angelina  \\\n",
       "0  0.0     0.0   0.0     0.0    0.0    0.0   0.0       0.0    0.0       0.0   \n",
       "1  0.0     0.0   0.0     0.0    0.0    0.0   0.0       0.0    0.0       0.0   \n",
       "2  0.0     0.0   0.0     0.0    0.0    0.0   0.0       0.0    0.0       0.0   \n",
       "3  0.0     0.0   0.0     0.0    0.0    0.0   0.0       0.0    0.0       0.0   \n",
       "4  0.0     0.0   0.0     0.0    0.0    0.0   0.0       0.0    0.0       0.0   \n",
       "\n",
       "   ...    winner  woman  women  work  world  wrong  year   yep  rationale  \\\n",
       "0  ...       0.0    0.0    0.0   0.0    0.0    0.0   0.0  0.00       like   \n",
       "1  ...       0.0    0.0    0.0   0.0    0.0    0.0   0.0  0.00    awesome   \n",
       "2  ...       0.0    0.0    0.0   0.0    0.0    0.0   0.0  0.01    awesome   \n",
       "3  ...       0.0    0.0    0.0   0.0    0.0    0.0   0.0  0.00       hate   \n",
       "4  ...       0.0    0.0    0.0   0.0    0.0    0.0   0.0  0.00       love   \n",
       "\n",
       "   label  \n",
       "0      1  \n",
       "1      1  \n",
       "2      1  \n",
       "3      0  \n",
       "4      1  \n",
       "\n",
       "[5 rows x 234 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89855072463768115"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(df_train.drop(['label','rationale'], axis =1),df_train['label'])\n",
    "clf.score(df_test.drop(['label','rationale'], axis =1),df_test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.909090909091\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
